---
title: "IM"
layout: post
---

#### 初次接触IM，需要了解的知识


TCP/IP 四层模型

1. 应用层 例如HTTP（超文本传输协议）、FTP（文件传输协议）、SMTP（简单邮件传输协议）等在这一层,直接和应用打交道。
2. 传输层 TCP、UDP 主要负责传输数据，TCP是可靠连接，UDP更加高效，也就是速度更快，但是可能有丢包。
3. 网络层 IP协议，用来确定发送发和接收方，负责数据从原地址传递到目标地址。
4. 数据链路层 负责在物理网络上建立和维护数据链路，常见MAC地址封装就在这层。

#### Websocket

Websocket是一种网络通信协议，他通过http进行协议升级，升级成功之后进行双向通信。
Websocket协议: ws://...

- 客户端通过 HTTP 请求发起 WebSocket 连接。服务器响应确认后，连接升级为 WebSocket。
  TCP 连接建立的三次握手
  1.客户端发送 syn = 1 建立连接的请求。seq number = 0；
  2.服务器端收到syn =1 的请求之后，会将ack = 1，发送给客户端。
  3.客户端收到服务器端ack =1 的请求之后，把 seq number = 1。
- 示例握手请求：

```
GET /chat HTTP/1.1
Host: example.com
Upgrade: websocket
Connection: Upgrade
Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==
Sec-WebSocket-Version: 13
```

- 具体请求抓包分析可发现：
  客户端会先发送一个特殊的HTTP请求，在请求头参数中添加Connection:Upgrade 和 Upgrade:websocket,来协商需要更换的协议，
  服务器收到之后回复code：101 确认理解客户端请求，并在回复包中添加Connection:Upgrade 和 Upgrade:websocket字段。
  之后以帧的形式进行数据的发送与接收。WebSocket的数据帧格式详细定义可参考  ![RFC6455 5.2节](https://datatracker.ietf.org/doc/html/rfc6455#section-5.2)

问题 Websocket 和socket 区别？     
websocket 是基于tcp的应用层协议，而socket是对tcp/ip 层的抽象接口。
websocket 采用frame 帧的形式进行数据传输，并且是全双工的。

#### reactor 反应器模式

1. JavaNIO 非阻塞IO模型，是IO多路复用模型的封装，屏蔽了各个操作系统的底层实现。

- Selector 它实现了IO多路复用，通过将事件注册，然后在内部的select方法进行监听各种事件是否就绪。
- Buffer 提供了高效的数据读写。
- Channel 负责通信的通道，常见有FileChannel、SocketChannel、ServerSocketChannel、DatagramChannel。

2. Reactor 则正是基于NIO来实现高并发的设计模式

- Reactor反应器线程 负责响应IO事件，并分发到Handler处理器
- Handlers处理器 非阻塞的处理业务逻辑
  常见的有单反应器模式和多反应器模式，而单反应器模式在有阻塞时候后续handle无法处理任务，从而性能低下。一般都采用多反应器模式，如下图：
  ![multi_reactor](/assets/nio_25.png)
  简单来说就是通过创建两个Selector，分别对应mainReactor和sunReactor，在mainReactor中只关心Accept事件，并在处理该事件的时候
  将数据通道注册到另外一个Selector上。
#### Netty

> Netty是一个异步事件驱动的网络应用程序框架，用于快速开发可维护的高性能协议服务器和客户端。
> 以高并发（Reactor模型），低延迟-传输快-零拷贝技术，可支持定制多种协议著称。

**核心组建**

**Channel**

Netty 网络操作抽象类，包括基本的I/O操作，如accept connect read write等，大大降低了直接使用socket类
的复杂性。

1. NioSocketChannel 异步的客户端TCP socket连接
2. NioServerSocketChannel 异步的服务器端TCP socket连接
3. NioDatagramChannel 异步的UDP连接

**EventLoop**

EventLoop 事件循环接口，负责监听网络事件并调用事件处理器进行相关I/O操作的处理。
EventLoop 内部持有NIO中的Selector，Channel将会被注册到EventLoop中，一个EventLoop可以监听
多个Channel，EventLoop是实现IO多路复用的核心，可以看作是Reactor模型中的mainReactor。

**ChannelFuture**

Netty中所有的IO操作都是异步的，不能立刻得知消息是否被正确处理。

Channel会注册到EventLoop中后会立即返回一个ChannelFuture对象，可以通过ChannelFuture
的addListener注册GenericFutureListener监听器来进行结果的监听。

**ChannelHandler** 消息的具体处理器
负责各种业务，读写事件，连接，解码编码，数据转换，业务逻辑等等，处理完毕之后将数据转发到ChannelPipeline中
的下一个ChannelHandler。

ChannelInboundHandler 处理入站io事件
ChannelOutboundHandler 处理出站io事件

或者使用适配器类，更加方便
ChannelInboundHandlerAdapter 处理入站io事件
ChannelOutboundHandlerAdapter 处理出站io事件
ChannelDuplexHandler用于处理入站和出站事件

**ChannelPipeline**    
Netty中每个Channel都有且仅有一个ChannelPipeline与之对应。
是一个链表，里边放的是ChannelHandler，可以在 ChannelPipeline 上通过 addLast() 方法添加一个或者多个ChannelHandler
，因为一个数据或者事件可能会被多个 Handler 处理。当一个 ChannelHandler 处理完之后就将数据交给下一个 ChannelHandler 。

在执行时，入站事件会从链表head往后传递到最后一个入站的handler（ChannelInboundHandler类型），出站事件会从链表tail往前传递到最前一个出站的handler（ChannelOutboundHandler类型），两种类型的handler在执行时互不干扰。如果Handler同时属于入站、出站Handler，则都会执行一次。

![p-1](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/cdcc1a59ab02429d9ebcdc82a9a9042a~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

ChannelHandlerContext 保存Channel相关的上下文信息。将Handler和Pipeline联系起来，实际上ChannelPipeline中直接存的是
ChannelHandlerContext，而每个ChannelHandlerContext里边包含着ChannelHandler。

![p-2](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4e5182ea2c7d419a8e2127f0b6aed7a7~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

**EventLoopGroup**

事件循环组，里边包含多个事件循环EventLoop。每个EventLoop通常包含1个Selector和1个事件循环线程，一个EventLoop可以绑定多个Channel，但是每个Channel只能被
一个EventLoop绑定，这样连接的IO事件就在专门的线程上处理，保证线程安全。

Netty Server端包含一个boss 和 一个worker，职责如下：
boss ：

1. select监听accept事件。
2. 处理到来的accept事件，与Client建立连接，生成一个SocketChannel，并将SocketChannel注册到某个
   Worker NioEventLoop的Selector上。
3. 处理任务队列中的任务，runAllTasks。任务队列中的任务包括用户调用eventloop.execute或schedule执行的任务，或者其它线程提交到该eventloop的任务。

worker：

1. select监听read，write事件。
2. 处理到来的read，write事件，在NioSocketChannel可读，可写事件发生时进行处理。
3. 处理任务队列中的任务，runAllTasks。

**TCP 粘包/拆包 的原因和解决办法**

原因：TCP是以流的方式来处理数据，底层会有一个缓冲区，一个完整的较大的包可能会被TCP拆分成多个包进行发送，也可能把多个小的包封装成一个大的数据包发送。
报头的选项字段有MSS（Maximum Segment Size，最大报文段大小）字段，规定一个TCP包最大可传输的字节数，一般是1500-20-20=1460字节，大于该大小时将发生拆包。

解决办法：使用Netty自带的解码器

1. LineBasedFrameDecoder : 发送端发送数据包的时候，每个数据包之间以换行符作为分隔，即\n或者\r\n，其工作原理是它依次遍历
   ByteBuf 中的可读字节，判断是否有换行符，然后进行相应的截取。
2. DelimiterBasedFrameDecoder : 可以自定义分隔符解码器，其实际上是一种特殊的DelimiterBasedFrameDecoder 解码器。
3. FixedLengthFrameDecoder: 固定长度解码器，它能够按照指定的长度对消息进行相应的拆包。需要约定每一个包的固定大小。
4. LengthFieldBasedFrameDecoder：将消息分为消息头和消息体。在头部中保存有当前整个消息的长度，只有在读取到足够长度的消息之后才算是读到了一个完整的消息。

通过自定义协议进行粘包和拆包处理。

**长链接和心跳机制**

在 TCP 保持长连接的过程中，可能会出现断网等网络异常出现，异常发生的时候， client 与 server
之间如果没有交互的话，它们是无法发现对方已经掉线的。为了解决这个问题, 我们就需要引入心跳机制 。
心跳机制的工作原理是: 在 client 与 server 之间在一定时间内没有数据交互时, 即处于 idle
状态时，客户端或服务器就会发送一个特殊的数据包给对方，当接收方收到这个数据报文后，也立即发送一个特殊的数据报文，回应发送方，此即一个
PING-PONG 交互。所以，当某一端收到心跳消息后，就知道了对方仍然在线，这就确保 TCP 连接的有效性

**Netty零拷贝技术**

> 零拷贝（Zero-Copy）是一种 I/O 操作优化技术，可以快速高效地将数据从文件系统移动到网络接口，而不需要将其从内核空间复制到用户空间。目前只有在使用
> NIO 和 Epoll 传输时才可使用该特性。

传统I/O 工作方式
![p-3](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f6c3a1a5de3640aeb3b8a8771ff3a810~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

零拷贝技术原理：
零拷贝主要是用来解决操作系统在处理 I/O 操作时，频繁复制数据的问题。关于零拷贝主要技术有 mmap+write、sendfile和splice等几种方式。

有现代操作系统都使用虚拟内存，使用虚拟地址取代物理地址，主要有以下几点好处：

多个虚拟内存可以指向同一个物理地址。
虚拟内存空间可以远远大于物理内存空间。

利用上述的第一条特性可以优化，可以把内核空间和用户空间的虚拟地址映射到同一个物理地址，这样在 I/O 操作时就不需要来回复制了。

**mmap/write 方式**

![p-4](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d3747aca11884a1a85708c0163c79a99~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)
整个流程的核心区别就是，把数据读取到内核缓冲区后，应用程序进行写入操作时，直接把内核的Read Buffer的数据复制到Socket
Buffer以便写入，这次内核之间的复制也是需要CPU的参与的

**sendfile**

![p-5](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d221a3a90a754ca9842f6324455638ea~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)
sendfile方式只有三次数据复制（其中只有一次 CPU COPY）以及2次上下文切换。