> 零拷贝（Zero-copy）技术是一种计算机操作系统中用于提高数据传输效率的优化策略。在传统的数据传输过程中，需要将数据从一个缓冲区拷贝到另一个缓冲区，然后再传输给目标。这涉及到多次的
> CPU 和内存之间的数据拷贝操作，会消耗 CPU 的时间和内存带宽。而零拷贝技术通过直接共享数据的内存地址，避免了中间的拷贝过程，从而提高了数据传输的效率。


## 传统 IO 执行流程

要搞明白零拷贝技术就要先搞清楚传统 IO 的执行流程，传统的 IO 的执行流程如下：       
![old_io](https://raw.githubusercontent.com/HaoDevZone/home/refs/heads/master/assets/old_io.webp)

**DMA**:（Direct Memory Access，直接内存访问）技术，绕过 CPU，直接在内存和外设之间进行数据传输。这样可以减少 CPU
的参与，提高数据传输的效率。

1. 在用户态向内核态发起read()系统调用请求
2. 内核缓冲区通过发起DMA IO请求从硬盘读取数据
3. DMA拷贝数据到内核缓冲区
4. 从内核缓冲区进行CPU拷贝到用户缓存区
5. 在用户缓冲区通过write()调用，将数据写入到Socket缓冲区
6. Socket缓冲区通过DMA拷贝将数据写入网卡
7. 网卡通知Socket缓冲区完成
8. Socket缓冲区通知用户缓存区Write()调用完成

传统IO 一共进行了4次拷贝，4次上下文切换

### 用户态和内核态

操作系统有用户态和内核态之分，这是因为计算机体系结构中的操作系统设计了两个不同的执行环境，以提供不同的功能和特权级别。

- 用户态（User Mode）是指应用程序运行时的执行环境。在用户态下，应用程序只能访问受限资源，如应用程序自身的内存空间、CPU
  寄存器等，并且不能直接访问操作系统的底层资源和硬件设备。
- 内核态（Kernel Mode）是指操作系统内核运行时的执行环境。在内核态下，操作系统具有更高的权限，可以直接访问系统的硬件和底层资源，如
  CPU、内存、设备驱动程序等。

## 零拷贝技术的实现

零拷贝技术可以利用 Linux 下的 MMap、sendFile 等手段来实现，使得数据能够直接从磁盘映射到内核缓冲区，然后通过 DMA
传输到网卡缓存，整个过程中 CPU 只负责管理和调度，而无需执行实际的数据复制指令。

### MMap

MMap（Memory Map）是 Linux 操作系统中提供的一种将文件映射到进程地址空间的一种机制，通过 MMap
进程可以像访问内存一样访问文件，而无需显式的复制操作。    
使用 MMap 可以把 IO 执行流程优化成以下执行步骤：   
![mmap](https://raw.githubusercontent.com/HaoDevZone/home/refs/heads/master/assets/mmap_io.webp)
传统的 IO 需要四次拷贝和四次上下文（用户态和内核态）切换，而 MMap 只需要三次拷贝和四次上下文切换，从而能够提升程序整体的执行效率，并且节省了程序的内存空间。

在Android中进行跨进程通信经常会见到Binder，他内部就采用了mmap提供高效共享内存，从而达到减少拷贝次数和上下文的切换，不过他是Android独有的，和上面所说的还
不太一样，这里简单说一下：
- 在 Binder 驱动中，服务端进程会事先调用 mmap 将服务端的用户空间的一段虚拟内存和内核空间的一段虚拟内存，映射到同一块物理内存上。这段物理内存，将作为一个缓冲区，
接收来自不同客户端的数据。
- 比如，客户端发送事务数据时，内核会通过 copy_from_user 将数据放进缓冲区，然后通知服务端。服务端只需要通过用户空间相应的虚拟地址，就能直接访问数据。
- 通常不会涉及到DMA操作。

### sendFile

在 Linux 操作系统中 sendFile() 是一个系统调用函数，用于高效地将文件数据从内核空间直接传输到网络套接字（Socket）上，从而实现零拷贝技术。这个函数的主要目的是减少
CPU 上下文切换以及内存复制操作，提高文件传输性能。

使用 sendFile() 可以把 IO 执行流程优化成以下执行步骤：   
![zero](https://raw.githubusercontent.com/HaoDevZone/home/refs/heads/master/assets/zero_copy_io.webp)

这个是sendFile的初始版本，在Linux内核为2.4以及以上的版本进行了优化，改进后的处理逻辑如下：
1. DMA将磁盘数据拷贝到内核缓冲区，向socket缓冲区追加当前内核缓冲区要发送数据的位置以及偏移量
2. DMA gather copy 根据内核缓冲区的地址和偏移量，直接将内核缓冲区的数据拷贝到网卡上
经过上述操作，其实就是对第4步的CPU拷贝进行了改进，只进行了两次拷贝就将数据发送出去了，CPU未参与，做到了真正的零拷贝。

NIO（New I/O）通道：java.nio.channels.FileChannel 提供了 transferTo() 和 transferFrom() 方法，底层就是sendFile系统调用，
可以直接将数据从一个通道传输到另一个通道，例如从文件通道直接传输到 Socket 通道，整个过程无需将数据复制到用户空间缓冲区，
从而实现了零拷贝。
## 小结

使用零拷贝技术可以减少 CPU 拷贝，及减少了上下文的切换带来的性能开销，提高了程序的整体执行效率，它们的区别对比如下表格所示：

|              | CPU拷贝（次数） | DMA拷贝（次数） | 上下文切换（此时） |
|:------------:|:---------:|:---------:|:---------:|
|     传统IO     |     2     |     2     |     4     |
|     MMap     |     1     |     2     |     4     |
| sendFile初始版本 |     1     |     2     |     2     |
| sendFile改进版本 |     0     |     2     |     2     |

### 答疑解惑Java NIO 中 FileChannel 的两种文件传输方式：transferTo 和使用 DirectByteBuffer 配合 read/write 方法，我该如何选择？

#### 两种方式的原理
1. FileChannel.transferTo
  - **定义：** 
    - FileChannel.transferTo(long position, long count, WritableByteChannel target) 将源文件的数据直接传输到目标通道（如另一个 FileChannel 或 SocketChannel）。     
  - **底层机制：**
    - 利用操作系统级别的 零拷贝（zero-copy） 技术。
    - 在 Linux 上，通常调用 sendfile 系统调用，直接在内核空间完成数据传输，避免用户态和内核态的多次拷贝。
    - 数据路径：磁盘 → 内核缓冲区 → 目标通道（如网络 socket 或文件）。        
  - **特点：**
    - 一次调用可传输大块数据（最大 2GB，具体受 OS 限制）。
    - 不需要手动管理缓冲区，API 简单。
    - 适合大文件传输或文件到网络的场景。
2. DirectByteBuffer 配合 read/write
  - **定义：**
    - 使用 ByteBuffer.allocateDirect(capacity) 创建直接缓冲区（DirectByteBuffer），通过 FileChannel.read 读取数据，再用 FileChannel.write 写入目标。     
  - **底层机制：**
    - DirectByteBuffer 分配在堆外内存（native memory），减少 JVM 垃圾回收压力。
    - read 和 write 调用操作系统的 read 和 write 系统调用：
    - 读取：磁盘 → 内核缓冲区 → 堆外缓冲区（DirectByteBuffer）。
    - 写入：堆外缓冲区 → 内核缓冲区 → 目标（如磁盘）。
    - 数据路径涉及用户态和内核态的拷贝（内核缓冲区 ↔ DirectByteBuffer）。      
  - **特点：**
    - 需要手动循环读取和写入，管理缓冲区。
    - 提供细粒度控制，可中途处理数据。
    - 适合需要操作数据的场景（如加密、压缩）。    
    
#### 性能对比      

1. 理论分析
- transferTo：      
  - 优势：  
    - 零拷贝：数据不经过用户态，直接在内核空间传输，减少 CPU 和内存拷贝开销。
    - 高效传输：一次系统调用可传输大块数据，上下文切换少。
  - 劣势：     
    - 不支持数据处理（纯透传）。
    - 在某些操作系统（如 Windows）或非标准通道上，可能退化为普通拷贝。    
- DirectByteBuffer + read/write：   
  - 优势：
    - 灵活性高，可在读写间处理数据。
    - DirectByteBuffer 避免 JVM 堆内存拷贝，性能优于堆内 ByteBuffer。     
  - 劣势：
    - 多次拷贝：每次 read 和 write 涉及内核态 ↔ 用户态的拷贝。
    - 循环开销：需多次系统调用，上下文切换多。
    - 缓冲区管理：小缓冲区增加调用次数，大缓冲区耗内存。

2. 性能测试数据   
- 场景：传输 1GB 文件（磁盘 → 磁盘）。
- 环境：Linux（支持 sendfile），SSD，Java 17。
- 开源测试参考（如 Apache Commons IO 和 Stack Overflow 讨论）：        
  - transferTo：       
    - 耗时：~500-800ms。
    - CPU 使用率：低（< 5%）。
    - 内存占用：几乎为 0（内核缓冲区）。     
  - DirectByteBuffer (8MB 缓冲区)：        
    - 耗时：~1000-1500ms。
    - CPU 使用率：中（10-20%）。
    - 内存占用：8MB（堆外）。    
- 结论：    
  - transferTo 通常比 DirectByteBuffer 快 1.5-2 倍，尤其在 Linux 上零拷贝优势明显。